{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import Entrez, Medline\n",
    "import pandas as pd\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "Entrez.email = \"sjdhhe@gmail.com\"\n",
    "\n",
    "def search_pubmed(query, max_results=1000):\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return record[\"IdList\"]\n",
    "\n",
    "def fetch_details(id_list, chunk_size=10):\n",
    "    records = \"\"\n",
    "    for i in range(0, len(id_list), chunk_size):\n",
    "        chunk_ids = id_list[i:i + chunk_size]\n",
    "        ids = \",\".join(chunk_ids)\n",
    "        try:\n",
    "            handle = Entrez.efetch(db=\"pubmed\", id=ids, rettype=\"medline\", retmode=\"text\")\n",
    "            chunk_records = handle.read()\n",
    "            handle.close()\n",
    "            records += chunk_records\n",
    "        except HTTPError as e:\n",
    "            print(f\"HTTPError: {e} - Skipping  IDs: {chunk_ids}\")\n",
    "            continue\n",
    "    return records\n",
    "\n",
    "def parse_records(records):\n",
    "    handle = records.splitlines(True)\n",
    "    parsed_records = list(Medline.parse(handle))\n",
    "    return parsed_records\n",
    "\n",
    "def extract_info(parsed_records):\n",
    "    data = []\n",
    "    for record in parsed_records:\n",
    "        pubmed_id = record.get(\"PMID\", \"\")\n",
    "        pubmed_link = f\"https://pubmed.ncbi.nlm.nih.gov/{pubmed_id}/\"\n",
    "        country = record.get(\"PL\", \"\")\n",
    "        authors = record.get(\"FAU\", [])\n",
    "        year = record.get(\"Year\", \"\")\n",
    "        affiliations = record.get(\"AD\", [])\n",
    "       \n",
    "        email_author_pairs = []\n",
    "        if isinstance(affiliations, list) and isinstance(authors, list):\n",
    "            for i, author in enumerate(authors):\n",
    "                author_emails = []\n",
    "                if i < len(affiliations): \n",
    "                    for line in affiliations[i].split(\";\"):\n",
    "                        if \"@\" in line:\n",
    "                            author_emails.append(line.strip())\n",
    "                \n",
    "                if not author_emails:\n",
    "                    author_emails.append(\"No emails found\")\n",
    "                \n",
    "                email_author_pairs.append({\"Author\": author, \"Emails\": author_emails})\n",
    "        \n",
    "        data.append({\n",
    "            \"PubMed ID\": pubmed_id,\n",
    "            \"PubMed Link\": pubmed_link,\n",
    "            \"Year\": year,\n",
    "            \"Country\": country,\n",
    "            \"Author-Email Pairs\": email_author_pairs\n",
    "        })\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    query = input(\"Input the query (Use only keywords): \")\n",
    "    id_list = search_pubmed(query)\n",
    "    records = fetch_details(id_list)\n",
    "    parsed_records = parse_records(records)\n",
    "    data = extract_info(parsed_records)\n",
    "\n",
    "    flat_data = []\n",
    "    for entry in data:\n",
    "        pubmed_id = entry[\"PubMed ID\"]\n",
    "        pubmed_link = entry[\"PubMed Link\"]\n",
    "        year = entry[\"Year\"]\n",
    "        country = entry[\"Country\"]\n",
    "        for pair in entry[\"Author-Email Pairs\"]:\n",
    "            flat_data.append({\n",
    "                \"PubMed ID\": pubmed_id,\n",
    "                \"PubMed Link\": pubmed_link,\n",
    "                \"Year\": year,\n",
    "                \"Country\": country,\n",
    "                \"Author\": pair[\"Author\"],\n",
    "                \"Emails\": \", \".join(pair[\"Emails\"])\n",
    "            })\n",
    "  \n",
    "    df = pd.DataFrame(flat_data)\n",
    "    save_name = input(\"Enter the name to save the file\")\n",
    "    df.to_csv(f\"{save_name}.csv\", index=False)\n",
    "    print(f\"Data saved to {save_name}.csv\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import Entrez, Medline\n",
    "import pandas as pd\n",
    "from urllib.error import HTTPError\n",
    "import re \n",
    "from difflib import get_close_matches\n",
    "\n",
    "Entrez.email = \"tutue@gmail.com\"\n",
    "\n",
    "disease_names = [\n",
    "    'cancer', 'melanoma', 'leukemia', 'lymphoma', 'carcinoma', 'sarcoma', 'brain tumor', 'breast cancer', 'prostate cancer', 'lung cancer', 'colorectal cancer', 'pancreatic cancer',\n",
    "    'liver cancer', 'ovarian cancer', 'cervical cancer', 'bladder cancer', 'kidney cancer', 'hodgkin lymphoma', 'non-hodgkin lymphoma', 'adenocarcinoma', 'squamous cell carcinoma',\n",
    "    'basal cell carcinoma', 'osteosarcoma', 'liposarcoma', 'glioblastoma', 'meningioma', 'small cell lung cancer', 'non-small cell lung cancer', 'hepatocellular carcinoma',\n",
    "    'renal cell carcinoma', 'testicular cancer', 'thyroid cancer', 'esophageal cancer', 'gastric cancer', 'head and neck cancer', 'pancreatic adenocarcinoma', 'multiple myeloma', 'chronic lymphocytic leukemia',\n",
    "    'diabetes', 'type 1 diabetes', 'type 2 diabetes', 'gestational diabetes', 'prediabetes', 'latent autoimmune diabetes in adults', 'maturity onset diabetes of the young',\n",
    "    'hypertension', 'primary hypertension', 'secondary hypertension', 'prehypertension', 'white-coat hypertension', 'malignant hypertension','asthma', 'allergic asthma', 'exercise-induced asthma', 'occupational asthma',\n",
    "    'nocturnal asthma', 'cough-variant asthma', 'brittle asthma', 'arthritis', 'osteoarthritis', 'rheumatoid arthritis', 'psoriatic arthritis', 'gout', 'ankylosing spondylitis', 'juvenile idiopathic arthritis', 'septic arthritis',\n",
    "    'cardiovascular disease', 'coronary artery disease', 'heart attack', 'angina', 'stroke', 'ischemic stroke', 'hemorrhagic stroke', 'heart failure', 'arrhythmia', 'atrial fibrillation',\n",
    "    'ventricular tachycardia', 'peripheral artery disease', 'aortic aneurysm', 'cardiomyopathy', 'congenital heart disease', \"alzheimer's disease\", \"early-onset alzheimer's\", \"late-onset alzheimer's\",\n",
    "    'vascular dementia', 'lewy body dementia', 'frontotemporal dementia', \"parkinson's disease\", \"idiopathic parkinson's disease\", 'atypical parkinsonism',\n",
    "    'multiple system atrophy', 'progressive supranuclear palsy', \"early-onset parkinson's\", \"parkinson's disease dementia\",\n",
    "    'chronic obstructive pulmonary disease', 'chronic bronchitis', 'emphysema', 'refractory asthma', 'kidney disease', 'chronic kidney disease', 'acute kidney injury', 'nephrotic syndrome',\n",
    "    'polycystic kidney disease', 'glomerulonephritis', 'liver disease', 'cirrhosis', 'hepatitis', 'hepatitis a', 'hepatitis b', 'hepatitis c', 'hepatitis d', 'hepatitis e', 'non-alcoholic fatty liver disease', 'alcoholic liver disease',\n",
    "    'liver cancer', 'depression', 'major depressive disorder', 'persistent depressive disorder', 'anxiety disorder', 'generalized anxiety disorder', 'panic disorder', 'social anxiety disorder', 'bipolar disorder',\n",
    "    'schizophrenia', 'obsessive-compulsive disorder', 'post-traumatic stress disorder', 'autoimmune disease', 'lupus', 'multiple sclerosis', \"crohn's disease\", 'ulcerative colitis',\n",
    "    'celiac disease', 'infectious disease', 'tuberculosis', 'hiv/aids', 'malaria', 'influenza', 'covid-19', 'pneumonia', 'neurological disorder', 'epilepsy', 'migraine', 'amyotrophic lateral sclerosis', \"huntington's disease\"\n",
    "]\n",
    "\n",
    "organism_terms = [\n",
    "    'homo sapiens', 'human', 'plant', 'mus musculus', 'mouse', 'rattus norvegicus', 'rat', 'escherichia coli', 'e. coli', 'saccharomyces cerevisiae', 'yeast', 'drosophila melanogaster', 'fruit fly', 'caenorhabditis elegans', 'worm',\n",
    "    'mycobacterium tuberculosis', 'staphylococcus aureus', 'influenza a virus', 'covid', 'sars-cov-2', 'plasmodium falciparum', 'hepatitis c virus', 'human immunodeficiency virus', 'hiv', 'zika virus', 'ebola virus', 'arabidopsis thaliana', \n",
    "    'thale cress','danio rerio', 'zebrafish', 'candida albicans', 'schizosaccharomyces pombe', 'fission yeast', 'neurospora crassa', 'streptococcus pneumoniae', 'pneumococcus', 'salmonella enterica', 'salmonella', 'clostridium difficile', \n",
    "    'chlamydia trachomatis', 'aspergillus fumigatus', 'oryza sativa', 'rice', 'zea mays', 'maize', 'corn', 'gallus gallus', 'chicken', 'canis lupus familiaris', 'dog', 'felis catus', 'cat', 'macaca mulatta', 'rhesus macaque', 'pan troglodytes', 'chimpanzee',\n",
    "]\n",
    "\n",
    "sample_terms = [\n",
    "    'blood', 'urine', 'plasma', 'serum', 'swab', 'tissue', 'biopsy', 'ffpe', 'formalin-fixed paraffin-embedded', 'saliva', 'sputum', 'cerebrospinal fluid', 'csf', 'stool', 'fecal sample', 'synovial fluid', 'bone marrow', 'amniotic fluid', \n",
    "    'bronchoalveolar lavage', 'bal', 'cell culture', 'cell lysate', 'dna', 'rna', 'protein extract', 'peripheral blood mononuclear cells', 'pbmc', 'hair', 'nail clippings', 'fresh frozen','skin scrape', 'buccal swab', 'fixed tissue',\n",
    "    'ascites fluid', 'pleural fluid', 'vitreous humor', 'aqueous humor', 'frozen tissue', 'cryopreserved sample', 'microbiome sample', 'metabolite extract', 'breast milk', 'colostrum', 'fast frozen', 'semen', 'seminal fluid', 'sweat',\n",
    "    'gastric fluid', 'bile', 'pancreatic fluid', 'lymph node aspirate', 'fine needle aspirate', 'fna', 'organoid', 'spheroid', 'exosome', 'extracellular vesicles', 'tumor microenvironment sample', 'single-cell suspension',\n",
    "    'paraffin section', 'histological section', 'environmental swab', 'surface swab', 'soil sample', 'water sample', 'plant tissue', 'leaf extract', 'biofilm', 'microbial culture'\n",
    "]\n",
    "\n",
    "def search_pubmed(query, max_results=1000):\n",
    "    handle = Entrez.esearch(db=\"pubmed\", term=query, retmax=max_results)\n",
    "    record = Entrez.read(handle)\n",
    "    handle.close()\n",
    "    return record[\"IdList\"]\n",
    "\n",
    "def fetch_details(id_list, chunk_size=10):\n",
    "    records = \"\"\n",
    "    for i in range(0, len(id_list), chunk_size):\n",
    "        chunk_ids = id_list[i:i + chunk_size]\n",
    "        ids = \",\".join(chunk_ids)\n",
    "        try:\n",
    "            handle = Entrez.efetch(db=\"pubmed\", id=ids, rettype=\"medline\", retmode=\"text\")\n",
    "            chunk_records = handle.read()\n",
    "            handle.close()\n",
    "            records += chunk_records\n",
    "        except HTTPError as e:\n",
    "            print(f\"HTTPError: {e} - Skipping IDs: {chunk_ids}\")\n",
    "            continue\n",
    "    return records\n",
    "\n",
    "def parse_records(records):\n",
    "    handle = records.splitlines(True)\n",
    "    parsed_records = list(Medline.parse(handle))\n",
    "    return parsed_records\n",
    "\n",
    "def extract_info(parsed_records):\n",
    "    data = []\n",
    "    for record in parsed_records:\n",
    "        pubmed_id = record.get(\"PMID\", \"\")\n",
    "        pubmed_link = f\"https://pubmed.ncbi.nlm.nih.gov/{pubmed_id}/\"\n",
    "        dp_field = record.get(\"DP\", \"\")\n",
    "        year_match = re.search(r\"\\b(19|20)\\d{2}\\b\", dp_field)\n",
    "        year = year_match.group(0) if year_match else \"\"\n",
    "        funding = record.get(\"GR\", [])\n",
    "        funding_str = \", \".join(funding) if funding else \"No funding information\"\n",
    "        \n",
    "        authors = record.get(\"FAU\", [])\n",
    "        affiliations = record.get(\"AD\", [])\n",
    "        \n",
    "        author_aff_pairs = []\n",
    "        for i, author in enumerate(authors):\n",
    "            if i < len(affiliations):\n",
    "                affiliation = affiliations[i]\n",
    "            else:\n",
    "                affiliation = affiliations[-1] if affiliations else \"\"\n",
    "            author_aff_pairs.append({\"Author\": author, \"Affiliation\": affiliation})\n",
    "        \n",
    "        data.append({\n",
    "            \"PubMed ID\": pubmed_id,\n",
    "            \"PubMed Link\": pubmed_link,\n",
    "            \"Year\": year,\n",
    "            \"Author-Aff Pairs\": author_aff_pairs,\n",
    "            \"Funding\": funding_str\n",
    "        })\n",
    "    return data\n",
    "\n",
    "def extract_aff(text):\n",
    "    email_pattern = r'[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}'\n",
    "    text = re.sub(email_pattern, '', text)\n",
    "    text = re.sub(r'Electronic address:', '', text)\n",
    "    parts = [part.strip() for part in text.split(\",\") if part.strip()]\n",
    "    \n",
    "    if len(parts) >= 3:\n",
    "        institute = parts[0]\n",
    "        state = parts[-2]\n",
    "        country = parts[-1]\n",
    "    elif len(parts) == 2:\n",
    "        institute = parts[0]\n",
    "        state = \"\"\n",
    "        country = parts[1]\n",
    "    elif len(parts) == 1:\n",
    "        institute = parts[0]\n",
    "        state = \"\"\n",
    "        country = \"\"\n",
    "    else:\n",
    "        institute = \"\"\n",
    "        state = \"\"\n",
    "        country = \"\"\n",
    "    return pd.Series([institute, state, country])\n",
    "\n",
    "def clean(data):\n",
    "    data[\"Email Only\"] = data[\"Affiliation\"].str.extract(r'([A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,})')\n",
    "    data[[\"Institute\", \"State\", \"Country\"]] = data[\"Affiliation\"].apply(extract_aff)\n",
    "    data[\"Email Only\"] = data[\"Email Only\"].fillna(\"No email found\")\n",
    "    return data\n",
    "\n",
    "def match_terms(text, terms):\n",
    "    found = set()\n",
    "    for word in terms:\n",
    "        if word.lower() in text:\n",
    "            found.add(word)\n",
    "    return list(found)\n",
    "\n",
    "def add_ass_data(data):\n",
    "    for idx, row in data.iterrows():\n",
    "        try:\n",
    "            fetch = Entrez.efetch(db=\"pubmed\", id=row[\"PubMed ID\"], rettype=\"medline\", retmode=\"text\")\n",
    "            record = list(Medline.parse(fetch))[0]\n",
    "            abstract = record.get(\"AB\", \"\").lower()\n",
    "            data.at[idx, \"Diseases\"] = \", \".join(match_terms(abstract, disease_names))\n",
    "            data.at[idx, \"Organisms\"] = \", \".join(match_terms(abstract, organism_terms))\n",
    "            data.at[idx, \"Samples\"] = \", \".join(match_terms(abstract, sample_terms))\n",
    "        except Exception as e:\n",
    "            data.at[idx, \"Diseases\"] = \"\"\n",
    "            data.at[idx, \"Organisms\"] = \"\"\n",
    "            data.at[idx, \"Samples\"] = \"\"\n",
    "    return data\n",
    "\n",
    "def main():\n",
    "    query = input(\"Input the query (Use only keywords): \")\n",
    "    id_list = search_pubmed(query)\n",
    "    records = fetch_details(id_list)\n",
    "    parsed_records = parse_records(records)\n",
    "    data = extract_info(parsed_records)\n",
    "\n",
    "    flat_data = []\n",
    "    for entry in data:\n",
    "        pubmed_id = entry[\"PubMed ID\"]\n",
    "        pubmed_link = entry[\"PubMed Link\"]\n",
    "        year = entry[\"Year\"]\n",
    "        funding = entry[\"Funding\"]\n",
    "        for pair in entry[\"Author-Aff Pairs\"]:\n",
    "            flat_data.append({\n",
    "                \"PubMed ID\": pubmed_id,\n",
    "                \"PubMed Link\": pubmed_link,\n",
    "                \"Year\": year,\n",
    "                \"Author\": pair[\"Author\"],\n",
    "                \"Affiliation\": pair[\"Affiliation\"],\n",
    "                \"Funding\": funding\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(flat_data)\n",
    "    cl_data = clean(df)\n",
    "    fin_data = add_ass_data(cl_data)\n",
    "    fin_data.to_csv(\"/Ext_Data.csv\", index=False)\n",
    "    return fin_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
